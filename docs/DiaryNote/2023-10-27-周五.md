## Self-Attention
- 根据一排input vector获得一排output vector
![image.png](https://raw.githubusercontent.com/alwaysmissin/picgo/main/20231027231815.png)
![image.png](https://raw.githubusercontent.com/alwaysmissin/picgo/main/20231027230924.png)
其余的计算方法一致
![image.png](https://raw.githubusercontent.com/alwaysmissin/picgo/main/20231027234758.png)
![image.png](https://raw.githubusercontent.com/alwaysmissin/picgo/main/20231030173858.png)
![image.png](https://raw.githubusercontent.com/alwaysmissin/picgo/main/20231030174135.png)

## transform for speech
![image.png](https://raw.githubusercontent.com/alwaysmissin/picgo/main/20231030175836.png)

## images
cnn是简化版的self attention
![image.png](https://raw.githubusercontent.com/alwaysmissin/picgo/main/20231030180314.png)
 