# 正则化的逻辑回归
## 特征映射
- 如果特征数量较少，可以使用特征映射的方式，利用现有的特征，通过一些复合，获得更多的特征

## 代价函数
- 相比普通的逻辑回归，多了一个正则项，利用这个正则项，惩罚模型的复杂度，限制模型的权重，促使模型选择更少的特征，从而达到降低过拟合的目的
- 计算流程：
	- 首先计算非正则化的逻辑回归的损失函数
	- 计算$\sum_{j=0}^{n - 1} \omega_j ^2$
	- 计算$\frac{\lambda}{2m}\sum_{j=0}^{n - 1} \omega_j ^2$
	- 将正则项加到普通的损失函数中

## 正则逻辑回归的梯度计算
- 与计算损失函数类似，在普通的计算梯度的基础上，添加一个正则项$\frac{\lambda}{m}\omega_j$
- 然后将其加到普通的梯度计算函数上

> 梯度下降的方式与普通逻辑回归中一致